{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import vectorize\n",
    "% matplotlib inline\n",
    "import json\n",
    "import time\n",
    "np.random.seed(32113)\n",
    "import feature_engineering_func as fe_func\n",
    "import cnn_func\n",
    "import ensemble_method_func as em_func\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as XGB\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data prep for ensemble method model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category = \"cat_word_ems\"\n",
    "filepath = \"./data/raw_data/full%2Fraw%2Fcat.ndjson\"\n",
    "df = pd.read_json(filepath, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 626.167340994 seconds ---\n"
     ]
    }
   ],
   "source": [
    "fe_func.feature_engineering_ensemble(df,category,60000,'word')\n",
    "#this creates new file in data folder \"./data/MY_feature_{}.pkl\".format(category)\n",
    "\n",
    "#if you want to work on image prediction run following:\n",
    "# fe_func.feature_engineering_ensemble(df,category,60000,'word')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data prep for CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 525.985871077 seconds ---\n"
     ]
    }
   ],
   "source": [
    "df_final = fe_func.feature_engineering_CNN(df,category,60000,'country')\n",
    "#this creates new file in data folder \"./data/{}_15.pkl\".format(category)\n",
    "\n",
    "#if you want to work on image prediction run following:\n",
    "# df_final = fe_func.feature_engineering_CNN(df,category,60000,'word')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## CNN image prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cat = pd.read_pickle('./data/cat_60000_CNN_15.pkl')\n",
    "df_tiger = pd.read_pickle('./data/tiger_60000_CNN_15.pkl')\n",
    "df_lion = pd.read_pickle('./data/lion_60000_CNN_15.pkl')\n",
    "df_dog = pd.read_pickle('./data/dog_60000_CNN_15.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cnn_func.py:304: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), activation=\"relu\", input_shape=(42, 28, 1...)`\n",
      "  model.add(Convolution2D(cnnp[0], 5, 5, activation='relu', input_shape=(42,28,1)))\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/models.py:851: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 81600 samples, validate on 20400 samples\n",
      "Epoch 1/20\n",
      "81600/81600 [==============================] - 62s - loss: 0.0794 - acc: 0.7797 - val_loss: 0.0600 - val_acc: 0.8347\n",
      "Epoch 2/20\n",
      "81600/81600 [==============================] - 61s - loss: 0.0558 - acc: 0.8487 - val_loss: 0.0520 - val_acc: 0.8574\n",
      "Epoch 3/20\n",
      "81600/81600 [==============================] - 62s - loss: 0.0468 - acc: 0.8768 - val_loss: 0.0483 - val_acc: 0.8703\n",
      "Epoch 4/20\n",
      "81600/81600 [==============================] - 61s - loss: 0.0392 - acc: 0.8972 - val_loss: 0.0440 - val_acc: 0.8842\n",
      "Epoch 5/20\n",
      "81600/81600 [==============================] - 61s - loss: 0.0336 - acc: 0.9137 - val_loss: 0.0432 - val_acc: 0.8859\n",
      "Epoch 6/20\n",
      "81600/81600 [==============================] - 61s - loss: 0.0289 - acc: 0.9275 - val_loss: 0.0417 - val_acc: 0.8925\n",
      "Epoch 7/20\n",
      "81600/81600 [==============================] - 61s - loss: 0.0252 - acc: 0.9367 - val_loss: 0.0413 - val_acc: 0.8939\n",
      "Epoch 8/20\n",
      "81600/81600 [==============================] - 61s - loss: 0.0224 - acc: 0.9442 - val_loss: 0.0436 - val_acc: 0.8894\n",
      "Epoch 9/20\n",
      "81600/81600 [==============================] - 61s - loss: 0.0211 - acc: 0.9475 - val_loss: 0.0416 - val_acc: 0.8954\n",
      "Epoch 10/20\n",
      "81600/81600 [==============================] - 61s - loss: 0.0191 - acc: 0.9528 - val_loss: 0.0401 - val_acc: 0.9004\n",
      "Epoch 11/20\n",
      "81600/81600 [==============================] - 61s - loss: 0.0177 - acc: 0.9563 - val_loss: 0.0408 - val_acc: 0.8981\n",
      "Epoch 12/20\n",
      "81600/81600 [==============================] - 61s - loss: 0.0169 - acc: 0.9579 - val_loss: 0.0403 - val_acc: 0.9017\n",
      "Epoch 13/20\n",
      "81600/81600 [==============================] - 61s - loss: 0.0161 - acc: 0.9600 - val_loss: 0.0413 - val_acc: 0.8996\n",
      "Epoch 14/20\n",
      "81600/81600 [==============================] - 61s - loss: 0.0151 - acc: 0.9628 - val_loss: 0.0411 - val_acc: 0.8992\n",
      "Epoch 15/20\n",
      "81600/81600 [==============================] - 61s - loss: 0.0146 - acc: 0.9641 - val_loss: 0.0411 - val_acc: 0.8980\n",
      "Epoch 16/20\n",
      "81600/81600 [==============================] - 61s - loss: 0.0143 - acc: 0.9648 - val_loss: 0.0409 - val_acc: 0.9012\n",
      "Epoch 17/20\n",
      "81600/81600 [==============================] - 61s - loss: 0.0134 - acc: 0.9672 - val_loss: 0.0412 - val_acc: 0.9009\n",
      "Epoch 18/20\n",
      "81600/81600 [==============================] - 61s - loss: 0.0134 - acc: 0.9666 - val_loss: 0.0409 - val_acc: 0.9022\n",
      "Epoch 19/20\n",
      "81600/81600 [==============================] - 61s - loss: 0.0133 - acc: 0.9677 - val_loss: 0.0415 - val_acc: 0.9027\n",
      "Epoch 20/20\n",
      "81600/81600 [==============================] - 61s - loss: 0.0127 - acc: 0.9691 - val_loss: 0.0412 - val_acc: 0.9019\n"
     ]
    }
   ],
   "source": [
    "ip_model,X_tr,y_tr,X_te,y_te = cnn_func.CNN_image_recognition(df_cat,df_tiger,df_lion,df_dog,sample=30000,binary=False,\\\n",
    "                        convlayer =64,neuron =100, batchsize =128, epoch =20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17888/18000 [============================>.] - ETA: 0s[0.041147707626249433, 0.90216666666666667]\n"
     ]
    }
   ],
   "source": [
    "score = ip_model.evaluate(X_te,y_te)\n",
    "print score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN country prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cat = pd.read_pickle('./data/cat_country_CNN.pkl')\n",
    "df_tiger = pd.read_pickle('./data/tiger_country_CNN.pkl')\n",
    "df_lion = pd.read_pickle('./data/lion_country_CNN.pkl')\n",
    "df_dog = pd.read_pickle('./data/dog_country_CNN.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000 8000 8000 7294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cnn_func.py:304: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), activation=\"relu\", input_shape=(42, 28, 1...)`\n",
      "  model.add(Convolution2D(cnnp[0], 5, 5, activation='relu', input_shape=(42,28,1)))\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/models.py:851: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21279 samples, validate on 5320 samples\n",
      "Epoch 1/30\n",
      "21279/21279 [==============================] - 16s - loss: 0.1869 - acc: 0.3182 - val_loss: 0.1809 - val_acc: 0.3648\n",
      "Epoch 2/30\n",
      "21279/21279 [==============================] - 16s - loss: 0.1739 - acc: 0.4143 - val_loss: 0.1743 - val_acc: 0.4077\n",
      "Epoch 3/30\n",
      "21279/21279 [==============================] - 16s - loss: 0.1577 - acc: 0.5032 - val_loss: 0.1651 - val_acc: 0.4684\n",
      "Epoch 4/30\n",
      "21279/21279 [==============================] - 16s - loss: 0.1346 - acc: 0.5971 - val_loss: 0.1613 - val_acc: 0.4887\n",
      "Epoch 5/30\n",
      "21279/21279 [==============================] - 16s - loss: 0.1111 - acc: 0.6854 - val_loss: 0.1562 - val_acc: 0.5241\n",
      "Epoch 6/30\n",
      "21279/21279 [==============================] - 16s - loss: 0.0900 - acc: 0.7573 - val_loss: 0.1576 - val_acc: 0.5342\n",
      "Epoch 7/30\n",
      "21279/21279 [==============================] - 16s - loss: 0.0727 - acc: 0.8078 - val_loss: 0.1491 - val_acc: 0.5664\n",
      "Epoch 8/30\n",
      "21279/21279 [==============================] - 16s - loss: 0.0592 - acc: 0.8500 - val_loss: 0.1475 - val_acc: 0.5756\n",
      "Epoch 9/30\n",
      "21279/21279 [==============================] - 16s - loss: 0.0490 - acc: 0.8795 - val_loss: 0.1455 - val_acc: 0.5889\n",
      "Epoch 10/30\n",
      "21279/21279 [==============================] - 16s - loss: 0.0408 - acc: 0.8999 - val_loss: 0.1453 - val_acc: 0.6013\n",
      "Epoch 11/30\n",
      "21279/21279 [==============================] - 16s - loss: 0.0355 - acc: 0.9151 - val_loss: 0.1471 - val_acc: 0.6000\n",
      "Epoch 12/30\n",
      "21279/21279 [==============================] - 16s - loss: 0.0316 - acc: 0.9232 - val_loss: 0.1464 - val_acc: 0.6028\n",
      "Epoch 13/30\n",
      "21279/21279 [==============================] - 16s - loss: 0.0264 - acc: 0.9375 - val_loss: 0.1499 - val_acc: 0.6024\n",
      "Epoch 14/30\n",
      "21279/21279 [==============================] - 16s - loss: 0.0245 - acc: 0.9430 - val_loss: 0.1496 - val_acc: 0.6028\n",
      "Epoch 15/30\n",
      "21279/21279 [==============================] - 16s - loss: 0.0225 - acc: 0.9469 - val_loss: 0.1493 - val_acc: 0.6102\n",
      "Epoch 16/30\n",
      "21279/21279 [==============================] - 16s - loss: 0.0213 - acc: 0.9493 - val_loss: 0.1526 - val_acc: 0.6077\n",
      "Epoch 17/30\n",
      "21279/21279 [==============================] - 16s - loss: 0.0199 - acc: 0.9524 - val_loss: 0.1540 - val_acc: 0.6081\n",
      "Epoch 18/30\n",
      "21279/21279 [==============================] - 16s - loss: 0.0189 - acc: 0.9553 - val_loss: 0.1506 - val_acc: 0.6124\n",
      "Epoch 19/30\n",
      "21279/21279 [==============================] - 16s - loss: 0.0176 - acc: 0.9586 - val_loss: 0.1551 - val_acc: 0.6122\n",
      "Epoch 20/30\n",
      "21279/21279 [==============================] - 16s - loss: 0.0175 - acc: 0.9577 - val_loss: 0.1527 - val_acc: 0.6160\n",
      "Epoch 21/30\n",
      "21279/21279 [==============================] - 16s - loss: 0.0160 - acc: 0.9618 - val_loss: 0.1546 - val_acc: 0.6177\n",
      "Epoch 22/30\n",
      "21279/21279 [==============================] - 16s - loss: 0.0157 - acc: 0.9617 - val_loss: 0.1542 - val_acc: 0.6130\n",
      "Epoch 23/30\n",
      "21279/21279 [==============================] - 16s - loss: 0.0153 - acc: 0.9631 - val_loss: 0.1564 - val_acc: 0.6122\n",
      "Epoch 24/30\n",
      "21279/21279 [==============================] - 16s - loss: 0.0146 - acc: 0.9643 - val_loss: 0.1545 - val_acc: 0.6147\n",
      "Epoch 25/30\n",
      "21279/21279 [==============================] - 16s - loss: 0.0143 - acc: 0.9654 - val_loss: 0.1559 - val_acc: 0.6179\n",
      "Epoch 26/30\n",
      "21279/21279 [==============================] - 16s - loss: 0.0147 - acc: 0.9631 - val_loss: 0.1566 - val_acc: 0.6152\n",
      "Epoch 27/30\n",
      "21279/21279 [==============================] - 16s - loss: 0.0138 - acc: 0.9671 - val_loss: 0.1548 - val_acc: 0.6218\n",
      "Epoch 28/30\n",
      "21279/21279 [==============================] - 16s - loss: 0.0126 - acc: 0.9688 - val_loss: 0.1562 - val_acc: 0.6192\n",
      "Epoch 29/30\n",
      "21279/21279 [==============================] - 16s - loss: 0.0127 - acc: 0.9690 - val_loss: 0.1584 - val_acc: 0.6150\n",
      "Epoch 30/30\n",
      "21279/21279 [==============================] - 16s - loss: 0.0133 - acc: 0.9669 - val_loss: 0.1560 - val_acc: 0.6186\n"
     ]
    }
   ],
   "source": [
    "cp_model,X_tr2,y_tr2,X_te2,y_te2 = cnn_func.CNN_country_prediction(df_cat,df_tiger,df_lion,df_dog,sample=30000,limit=8000,\n",
    "                                binary=False, convlayer =64,neuron =100, \\\n",
    "                                            batchsize =128, epoch =30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4640/4695 [============================>.] - ETA: 0s\n",
      "CNN Country prediction accuracy: 62.7050053121 percent\n"
     ]
    }
   ],
   "source": [
    "score2 = cp_model.evaluate(X_te2,y_te2)\n",
    "print \"\\nCNN Country prediction accuracy: {} percent\".format(score2[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble method Country prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_en = pd.read_pickle('./data/MY_feature_cat_country_ems.pkl')\n",
    "df_tiger_en = pd.read_pickle('./data/MY_feature_tiger_country_ems.pkl')\n",
    "df_lion_en = pd.read_pickle('./data/MY_feature_lion_country_ems.pkl')\n",
    "df_dog_en = pd.read_pickle('./data/MY_feature_dog_country_ems.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44278 39086 44220 68621\n",
      "196205\n",
      "number of images for US:8000, BR:8000, RU:8000, KR:7276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df,Y,df_US,df_BR,df_RU,df_KR = em_func.data_preparer_ensemble(df_cat_en,df_tiger_en,\\\n",
    "                                            df_lion_en,df_dog_en, lbl = 'countrycode', \\\n",
    "                                                        countries=['US','BR','RU','KR'],\\\n",
    "                                    words=['cat','tiger','lion','dog',sample=30000, limit = 8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr3,X_te3,y_tr3,y_te3 =train_test_split(new_df,Y,test_size = 0.15, \\\n",
    "                                                    random_state=831713, stratify = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Country prediction accuracy: 43.7979539642 percent\n"
     ]
    }
   ],
   "source": [
    "xgb =XGB.XGBClassifier(max_depth=1, n_estimators=1000, learning_rate=0.2)\n",
    "xgb.fit(np.array(X_tr3),np.array(y_tr3))\n",
    "score = xgb.score(np.array(X_te3),np.array(y_te3))\n",
    "print \"XGBoost Country prediction accuracy: {} percent\".format(score*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRID SEARCH for country prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_test = XGB.XGBClassifier()\n",
    "parameters ={'max_depth':[1], 'n_estimators':[1000,1500,2000],'learning_rate':[0.1,0.2]}\n",
    "Gsearch = GridSearchCV(xgb,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1054.72330093 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "Gsearch.fit(X_tr3,y_tr3)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.2, max_delta_step=0, max_depth=1,\n",
       "       min_child_weight=1, missing=None, n_estimators=1000, nthread=-1,\n",
       "       objective='multi:softprob', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance for Country prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind = np.argsort(xgb.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp = [X_te3.columns[i] for i in ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Top 15 important features for country prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['direction_stroke1',\n",
       " 'Y_1',\n",
       " 'ave_time_per_stroke',\n",
       " 'direction_stroke5',\n",
       " 'direction_stroke4',\n",
       " 'Ymax',\n",
       " 'final_time',\n",
       " 'direction_stroke3',\n",
       " 'direction_stroke0',\n",
       " 'ave_datapoints_per_stroke',\n",
       " 'time_1',\n",
       " 'X_0',\n",
       " 'direction_stroke2',\n",
       " 'time_stroke0',\n",
       " 'total_number_of_datapoints']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp[-15:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Ensemble method Image Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cat_en2 = pd.read_pickle('./data/MY_feature_cat_word_ems.pkl')\n",
    "df_tiger_en2 = pd.read_pickle('./data/MY_feature_tiger_word_ems.pkl')\n",
    "df_lion_en2 = pd.read_pickle('./data/MY_feature_lion_word_ems.pkl')\n",
    "df_dog_en2 = pd.read_pickle('./data/MY_feature_dog_word_ems.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of images for df_cat: 60000\n",
      "total number of images for df_tiger: 60000\n",
      "total number of images for df_lion: 60000\n",
      "total number of images for df_dog: 60000\n",
      "30000 30000 30000 30000\n"
     ]
    }
   ],
   "source": [
    "X2,Y2 = em_func.data_preparer_ensemble(df_cat_en2,df_tiger_en2, df_lion_en2,df_dog_en2, \\\n",
    "                                          lbl = 'word', countries=['US','BR','RU','KR'],\\\n",
    "                                                     words=['cat','tiger','lion','dog'],\\\n",
    "                                                            sample=30000, limit = 8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr4,X_te4,y_tr4,y_te4 =train_test_split(X2,Y2,test_size = 0.15, \\\n",
    "                                                    random_state=831713, stratify = Y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRID SEARCH for image recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_test2 = XGB.XGBClassifier()\n",
    "parameters ={'max_depth':[1], 'n_estimators':[5000],'learning_rate':[0.25,0.5]}\n",
    "Gsearch2 = GridSearchCV(xgb_test2,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "Gsearch2.fit(X_tr4,y_tr4)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Gsearch2.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost  image recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost image recognition accuracy: 79.1222222222 percent\n"
     ]
    }
   ],
   "source": [
    "xgb2 =XGB.XGBClassifier(max_depth=1, n_estimators=5000, learning_rate=0.25)\n",
    "xgb2.fit(np.array(X_tr4),np.array(y_tr4))\n",
    "score = xgb2.score(np.array(X_te4),np.array(y_te4))\n",
    "print \"XGBoost image recognition accuracy: {} percent\".format(score*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance for image recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind2 = np.argsort(xgb2.feature_importances_)\n",
    "imp2 = [X_te4.columns[i] for i in ind2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Top 15 important features for image recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time_stroke0',\n",
       " 'direction_stroke4',\n",
       " 'ave_time_per_stroke',\n",
       " 'direction_stroke7',\n",
       " 'direction_stroke5',\n",
       " 'Y_0',\n",
       " 'total_time_drawing',\n",
       " 'direction_stroke2',\n",
       " 'direction_stroke1',\n",
       " 'datapoint_percentage_stroke0',\n",
       " 'direction_stroke6',\n",
       " 'X_0',\n",
       " 'datapoint_percentage_stroke2',\n",
       " 'datapoint_percentage_stroke1',\n",
       " 'Ymax']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp2[-15:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
